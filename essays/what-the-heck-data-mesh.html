<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="date" content='2021-06-08'>
<meta name="viewport" content="width=device-width,height=device-height,initial-scale=1.0"/>
<meta property="og:type" content="website" />
<meta property="og:title" content="What the Heck is a Data Mesh?!" />
<meta property="og:description" content="I got sucked into a data mesh
Twitter thread this weekend (it‚Äôs worth a read if you haven‚Äôt seen it).
Data meshes have clearly struck a nerve. Some don‚Äôt understand them,
while others believe they‚Äôr" />
<meta property="og:image" content="https://cnr.sh/img/og-img.png" /><link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üí¨</text></svg>">
<link rel="alternate" type="application/rss+xml" href="https://cnr.sh/rss.xml" title="Chris Riccomini's RSS Feed"><title>What
the Heck is a Data Mesh?! | Chris Riccomini</title>
<style>
@import url('https://fonts.googleapis.com/css2?family=Lora:wght@400;700&family=Roboto+Condensed:wght@700&display=swap');
body {padding: 1.25rem 0em; margin: 0em; font-family: 'Lora', serif; font-size: 14pt; line-height: 1.75;}
h1, h2, h3, h4 {font-family: 'Roboto Condensed', sans-serif; margin: 0em; line-height: 1.25;}
h1 {font-size: 30pt;}
a {color: #ff0080; text-decoration: none; font-weight: bold;}
pre > code {overflow-x: auto; width: 100%; display: inline-block;}
div.home {position: fixed; font-size: 15pt; padding: .5em; line-height: 0em; background-color: #333;}
div.social {position: fixed; font-size: 15pt; padding: .5em; line-height: 0em; right: 1.5em;}
div.title {text-align: center;}
div.main {width: 32em; margin: 0em auto;}
div.intro {width: 30em; margin: 0em auto;}
div.article:first-letter {float: left; margin: .125em .25em; font-size: 4em; line-height: 1;}
div.links {width: 40em; margin: 0em auto;}
div.links table {border-spacing: 0em 0em; margin: 1em 0em;}
div.links td.link-date {text-align: right; width: 10em; padding-right: .5em; vertical-align: top;}
div.links span.link-date {display: none;}
i.social {color: #ccc;}
i.home {color: white;}
div.intro p:first-of-type {font-size: 22pt;}
div.article p:first-of-type {font-size: 18pt;}
div.article blockquote > p:first-of-type {font-size: 14pt;}
div.article img {width: 100%;}
div.promo {margin: 0rem auto 1.25rem auto; width: 50rem; font-family: helvetica; text-align: center; top: 0px; left: 0px; background-color: black; color: white; font-size: .925rem; letter-spacing: .075rem; padding: .5em;}
@media screen and (min-width : 0px) and (max-width : 767px){
body {padding: 0em;}
div.main {width: auto; padding: 4em 2em;}
div.intro {width: auto; padding: 0em 3em;}
div.home {position: absolute;}
div.social {display: none;}
span.by {display: block; margin-top: .5em;}
div.links {padding-top: 1em; width: auto; padding: 4em 2em;}
div.links td.link-date {display: none;}
div.links span.link-date {display: block;}
div.links table {border-spacing: 0em 1em; margin: 0em;}
div.promo {width: auto; padding: 1rem 4rem; }
}</style>
<script defer src="https://kit.fontawesome.com/72c21ff1f4.js" crossorigin="anonymous"></script>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-3R91BN0RW0"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-3R91BN0RW0');
</script></head>
<body>
<div class="home">
<a href="/"><i class="home fas fa-home"></i></a>
</div>
<div class="social">
<a href="https://twitter.com/criccomini"><i class="social fab fa-twitter"></i></a>
</div><div class="main">
<div class="title">
<h1>What the Heck is a Data Mesh?!</h1>
<span class="by">Chris Riccomini on June 8, 2021</span>
</div>
<div class="article">
<p>I got sucked into a data mesh <a
href="https://twitter.com/fulhack/status/1400461693197570051">Twitter
thread</a> this weekend (it‚Äôs worth a read if you haven‚Äôt seen it). Data
meshes have clearly struck a nerve. Some don‚Äôt understand them, while
others believe they‚Äôre a bad idea. Yet, ‚ÄúDemystifying Data Mesh‚Äù and
‚ÄúPutting Data Mesh to Work‚Äù articles abound.</p>
<p>To understand the confusion, I re-read <a
href="https://twitter.com/zhamakd">Zhamak Dehghani</a> ‚Äôs <a
href="https://martinfowler.com/articles/data-monolith-to-mesh.html">original</a>
and <a
href="https://martinfowler.com/articles/data-mesh-principles.html">follow-on</a>
posts. Zhamak is the creator of the data mesh. In her second post she
identifies <a
href="https://martinfowler.com/articles/data-mesh-principles.html#CorePrinciplesAndLogicalArchitectureOfDataMesh">four
data mesh principles</a>:</p>
<ol type="1">
<li>Domain-oriented decentralized data ownership and architecture</li>
<li>Data as a product</li>
<li>Self-serve data infrastructure as a platform</li>
<li>Federated computational governance</li>
</ol>
<p>I believe that putting these principles on equal footing creates
confusion. The second principle‚Äîdata as a product‚Äîis the motivating
reason for a data mesh and worth considering on its own. Once we explore
what ‚Äúdata as a product‚Äù is, we can discuss the implications: the need
for decentralization, self-serve infrastructure, and federated
governance.</p>
<h2 id="data-as-a-product">Data as a Product</h2>
<p>Application data has customers just like any other product. Data
scientists, business analysts, finance, sales operations, product
managers, and engineers all use application data. Machine learning
models, charts, graphs, reports, and even other web services are all
built on top of application data. And application data is being
increasingly exposed to paying customers as part of the ‚Äúreal‚Äù product
(Stripe‚Äôs <a href="https://stripe.com/sigma">Sigma</a> is an
example).</p>
<p>Yet, organizations don‚Äôt think of data as a product. While
development teams spend time documenting, versioning, refactoring, and
curating web service data models and APIs, data goes largely ignored.
Organizations with ETL pipelines either directly expose web service data
models, or have a centralized team that builds a manicured data
warehouse. Data models well suited for low-latency web services are
difficult for humans to work with. A centralized data warehousing team
simply hides the suffering behind a team of hapless data engineers left
with the sisyphean task of interpreting internal schemas, chasing data
as it‚Äôs migrated, building their own‚Äîoften inaccurate‚Äîdata models, and
desperately propping up a monolithic data pipeline. It would be madness
to propose centralizing all service API and data modeling, yet that‚Äôs
what we‚Äôve done with data.</p>
<p>What we need, instead, is for organizations to treat data with the
same care that they treat any other public facing API. Data must have
well-defined schemas, be versioned, enforce compatibility guarantees, be
well documented, and so on. Basically, organizations need to act like
their data is being used by humans, because it is!</p>
<p>But how do you build a data product? I‚Äôve already said that
centralized teams don‚Äôt do a good job of this; we‚Äôve tried it for
decades and it just doesn‚Äôt work well. Data products must be built in a
decentralized manner by the teams that own the data; they‚Äôre the ones
that understand it. Decentralization is where the other three principles
come in, and that‚Äôs where I think a lot of the confusion lies. To
demystify these principles, I‚Äôll use the modern service stack for
comparison.</p>
<h2 id="modern-service-stacks">Modern Service Stacks</h2>
<p>Modern service stacks have a few important characteristics:</p>
<ol type="a">
<li>Decentralized microservice API ownership and architecture</li>
<li>Self-serve service infrastructure as a platform</li>
<li>Federated service governance</li>
</ol>
<p>These characteristics map to data mesh principles (1), (3), and
(4).</p>
<p>It should surprise no one that a modern service stack is
decentralized (a). Such stacks typically have hundreds or thousands of
different services owned by dozens or hundreds of teams. Each team is
left to define, build, and own its APIs.</p>
<p>Teams also deploy and monitor their own services (b). Self-deployment
increases feature delivery velocity: developers aren‚Äôt stuck waiting on
a separate team of button-pushers to deploy changes. And a centralized
team isn‚Äôt left deploying software that they don‚Äôt understand (sound
familiar?).</p>
<p>But application developers don‚Äôt always have the skills necessary to
define well-factored APIs or troubleshoot complex deployment issues.
Federated governance (c) through service infrastructure teams, DevOps
culture, and embedded site reliability engineers (SREs) acts as a
counter-weight to decentralization.</p>
<p>Centralized teams define standard serialization formats, service
frameworks, and API modeling and compatibility rules. These ‚Äúservice
infrastructure‚Äù or ‚Äúservice platform‚Äù teams write tools to enforce the
standards and assist application developers in generating clean service
scaffolding. And committee-style design reviews emerge to give
application developers API modeling guidance.</p>
<p>Similarly, DevOps culture and embedded site reliability engineers
(SREs) have emerged to help application developers deploy their changes
reliably. DevOps provides guard rails through automated tooling, so
developers can confidently deploy their services using blue/green
deployments, canaries, dynamic pre-production environments, and A/B
splits. Highly evolved DevOps organizations might even have monitoring
with auto-rollback if error rate increases. In addition, site
reliability engineers can be embedded on application development teams
to assist with operational issues and tooling development.</p>
<p>A data mesh takes service stack best-practices and applies them to
the data layer. Not only should application development teams define
APIs for their business logic (in the form of web services); they should
do so for their data as well. The infrastructure and culture needed for
the two are remarkably similar.</p>
<h2 id="infrastructure">Infrastructure</h2>
<p>Application teams need infrastructure to define their data product,
to transform their internal data into the data product format, and to
transfer the data product to its destination database(s).</p>
<p>Data product schemas are defined using standard formats like Protocol
buffers, Avro, or JSON schema. Schema metadata‚Äîversioning, ownership,
lineage, comments, usage, and so on‚Äîare attached using data catalogs
like <a href="https://github.com/amundsen-io/amundsen">Amundsen</a>, <a
href="https://github.com/linkedin/datahub">Datahub</a>, and <a
href="https://github.com/MarquezProject/marquez">Marquez</a> (the space
is booming). Compatibility rules are enforced using tools like <a
href="https://www.confluent.io/">Confluent</a>‚Äôs <a
href="https://docs.confluent.io/platform/current/schema-registry/avro.html#schema-evolution-and-compatibility">schema
registry</a> or home-grown validators that are inserted into the CI/CD
pipeline to run pre-commit checks.</p>
<p>Developers quickly find that the data products they wish to expose
don‚Äôt match their internal database schemas (something their data
engineers could have told them a decade ago). A data pipeline is needed
to transfer and transform data into its user-facing format.</p>
<p>Data pipelines aren‚Äôt new‚Äîit‚Äôs ETL‚Äîbut the <em>who</em> is new.
Centralized teams aren‚Äôt responsible for the transfer and
transformation, application developers are. A decentralized data
platform must be built. Automated pipeline generation tools can be built
on top of <a href="https://airflow.apache.org/">Airflow</a>, <a
href="https://www.prefect.io/">Prefect</a>, and <a
href="https://www.getdbt.com/">dbt</a>. Application engineers can define
their data products and transformations, and tools can auto-generate
their transformation workflows.</p>
<p>If the data pipeline is stream-based, transfer and transformation are
done through streaming systems and stream processors like <a
href="https://kafka.apache.org/0102/documentation/streams/">Kafka
Streams</a>, <a href="https://flink.apache.org/">Flink</a>, and so on.
Tooling to auto-generate simple transformations from configuration needs
to be built here, too. Best practices like the <a
href="https://debezium.io/blog/2019/02/19/reliable-microservices-data-exchange-with-the-outbox-pattern/">outbox
pattern</a> are also emerging.</p>
<p>Deployment will need to be automated in the same fashion as service
CI/CD pipelines. The same deployment and orchestration tooling that
exists for microservices can be repurposed for distributed data
pipelines.</p>
<p>GDPR and its offshoots are real. Sensitive data should not be
exposed. Security and compliance have historically been enforced
centrally through the data warehousing team. Now, we‚Äôll need
infrastructure and tooling to do this. Data catalogs can play a role
here, as can automated detection tools like <a
href="https://cloud.google.com/dlp">Google Cloud‚Äôs DLP</a> solution.
Access control (who gets access to what data) will need to be enforced
through policy codified in configuration.</p>
<p>There are of course other infrastructure requirements; the <a
href="https://datakitchen.io/what-is-dataops/">DataOps</a> movement
covers a lot of them. I‚Äôm not being exhaustive here, the point is that
many of the same infrastructure requirements exist for data mesh as
exist for service stacks, and there are many tools to address them.</p>
<p>If you forced me to define the infrastructure for a minimum-viable
data mesh, I‚Äôd say:</p>
<ul>
<li><strong>A schema definition tool</strong> Protocol buffers, Avro,
JSON schema</li>
<li><strong>A transfer/transformation tool</strong> Airflow, Prefect,
Kafka Streams, Kafka Connect, Flink</li>
<li><strong>A data warehousing tool</strong> Snowflake, BigQuery</li>
<li><strong>A data catalog</strong> Amundsen, Datahub, Marquez</li>
</ul>
<h2 id="culture">Culture</h2>
<p>Technology alone doesn‚Äôt make a data mesh. The shift to decentralized
data pipelines and data warehouses requires cultural change within the
organization.</p>
<p>Just as application developers might not have all the skills to
define well-factored service APIs, they probably won‚Äôt have the skills
to define a well-factored data product or run a data pipeline. Again,
the same problems exist for service oriented architectures (SOAs), and
the same solutions can be applied. Data infrastructure teams, DataOps
culture, and embedded data engineers help to bridge the skill gap and
provide guard rails.</p>
<p>‚ÄúData infrastructure‚Äù or ‚Äúdata platform‚Äù teams need to be created to
build the distributed data platform infrastructure‚Äîthe stuff listed in
the <em>infrastructure</em> section above. Infrastructure teams must
also build DataOps tooling to provide guard rails and instill DevOps
best practices. Data quality checks and monitoring (<a
href="https://www.anomalo.com/">Anomalo</a> and <a
href="https://www.bigeye.com/about/">BigEye</a>), pipeline tests (both
<a
href="https://docs.getdbt.com/docs/building-a-dbt-project/tests">schema
and data</a>), and standard service deployment practices are used.
DataOps focuses heavily on Agile culture, and espouses lean
manufacturing best practices and statistical process control (SPC); it‚Äôs
as much culture as tooling.</p>
<p>Centralized committees define standard serialization formats,
transformation frameworks, and data modeling and compatibility rules.
Design committees emerge to give application developers data modeling
guidance for their data products. We had teams responsible for reviewing
and providing guidance for both service APIs and data products nearly a
decade ago at LinkedIn.</p>
<p>And just as SREs are embedded in application development teams, so
too can data engineers be. Embedded data engineers are responsible for
defining data products, maintaining data pipelines, and building data
tooling within the team.</p>
<p>Above all, application teams need to buy into the idea that data is a
product they need to invest in. This is a hard sell; it‚Äôs something that
gets in the way of their ‚Äúreal‚Äù work. Finding champions within the org
can help. And as user-facing data products like Stripe‚Äôs Sigma grow
pervasive, application teams will be exposed to the pain data
warehousing teams have been feeling. Engineers will begin demanding data
products on their own; it will be intuitive to them‚Äîit‚Äôs the same stuff
they‚Äôve been doing with service oriented architectures and DevOps.</p>
<p>If you forced me to define the culture for a minimum-viable data
mesh, I‚Äôd say:</p>
<ul>
<li>Application teams accept responsibility for building data
products</li>
<li>DevOps best practices are adopted for data products and data
infrastructure</li>
<li>Data product standards are well defined and programmatically
enforced</li>
</ul>
<h2 id="pitfalls">Pitfalls</h2>
<p>As with a modern service stack, a data mesh is bound to have
pitfalls. Lack of standards and REST pedants are a real problem.</p>
<p>Many service stacks begin with no clear set of standards. Teams build
services using their own frameworks and tools, and don‚Äôt adhere to REST
or gRPC best practices. What emerges is a distributed monolith with
poorly documented APIs.</p>
<p>Work in software long enough, and you‚Äôll eventually come across the
abrasive REST obsessive. The person ranting about nouns, verbs, URNs,
and the ‚Äúright‚Äù way to do REST. Stuff like the <a
href="https://martinfowler.com/articles/richardsonMaturityModel.html">Richardson
Maturity Model</a> (nothing against this, but some people get way too
into it).</p>
<p>Agile ninjas and blackbelts emerge on the culture-side to dictate how
to ‚Äúdo‚Äù Agile. Certifications are created and thick tomes of
gobbledygook are written so vendors and consultants can make a buck.</p>
<p>All of these risks exist for data meshes, too. This doesn‚Äôt mean that
the data mesh is a bad idea any more that it means service oriented
architecture or Agile are bad ideas. They‚Äôre just tools and practices
that can be used or misused, like any other. Start with data products
and see where it takes you.</p>
<h2 id="notes">Notes</h2>
<ul>
<li>I use data warehouse, data mart, and data lake interchangeably here.
Zhamak uses the term <em>data plane</em>.</li>
<li>Thanks to Dmitriy Ryaboy, Gunnar Morling, Kishore Gopalakrishna, and
Erik Bernhardsson.</li>
<li>I use ‚Äúmodern service stack‚Äù and SOA interchangeably.</li>
<li>I am not involved with the data mesh project in any way. I‚Äôm a fan
of Zhamak‚Äôs work.</li>
<li>I am investor in several companies related to this post (Prefect,
Amundsen, Confluent, Stemma).</li>
</ul>
</div>
<form style="background-color: #eee; padding:1em; text-align:center;" action="https://tinyletter.com/criccomini" method="post" target="popupwindow" onsubmit="window.open('https://tinyletter.com/criccomini', 'popupwindow', 'scrollbars=yes,width=800,height=600');return true">
<h1><label for="tlemail">Never Miss a Post</label></h1>
<span class="by">Subscribe to my newsletter!</span>
<p style="margin-bottom: .35em;">
<input type="text" style="width:140px" name="email" id="tlemail" placeholder="your@email.com" />
<input type="hidden" value="1" name="embed"/><input type="submit" value="Subscribe" />
</p>
</form></div>
</body>
</html>